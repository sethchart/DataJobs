{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following this resource\n",
    "https://www.kdnuggets.com/2019/09/overview-topics-extraction-python-latent-dirichlet-allocation.html\n",
    "\n",
    "https://github.com/FelixChop/MediumArticles/blob/master/LDA-BBC.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading and saving data\n",
    "import pickle\n",
    "\n",
    "# Progress\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting\n",
    "import plotly.express as px\n",
    "\n",
    "# Latent Dirichlet Allocation\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "\n",
    "# Build corpus\n",
    "from gensim import corpora\n",
    "\n",
    "# Saving Models\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Combinations\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 20\n",
    "def get_model(num_topics):\n",
    "    file_path = f'../model/LDA-{num_topics}topics'\n",
    "    lda_model = LdaModel.load(file_path)\n",
    "    return lda_model\n",
    "\n",
    "lda_model = get_model(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(lda_model):\n",
    "    topics = lda_model.show_topics(num_topics = -1, num_words=20, formatted=False)\n",
    "    return topics\n",
    "\n",
    "topics = get_topics(lda_model)\n",
    "topic = topics[0]\n",
    "topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    similarity = len(intersection)/len(union)\n",
    "    return similarity\n",
    "\n",
    "test_set1 = {1, 2, 3}\n",
    "test_set2 = {2, 3, 4}\n",
    "assert jaccard_similarity(test_set1, test_set2) == 1/2, \"Should return 1/2.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_word_set(topic):\n",
    "    word_tuple_list = topic[1]\n",
    "    word_set = {word_tuple[0] for word_tuple in word_tuple_list}\n",
    "    return word_set\n",
    "\n",
    "word_set = topic_word_set(topic)\n",
    "word_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_jaccard_similarity(topics):\n",
    "    N = len(topics)\n",
    "    similarity_list = []\n",
    "    combs = combinations(topics, 2)\n",
    "    for topic1, topic2 in combs:\n",
    "        set1 = topic_word_set(topic1)\n",
    "        set2 = topic_word_set(topic2)\n",
    "        similarity_list.append(jaccard_similarity(set1, set2))\n",
    "    mean_similarity = np.mean(similarity_list)\n",
    "    return mean_similarity\n",
    "\n",
    "mean_jaccard_similarity(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed_data.pkl', mode='rb') as file:\n",
    "    data_records = pickle.load(file)\n",
    "\n",
    "tokens = [post['description_tokens'] for post in data_records]\n",
    "dictionary_LDA = corpora.Dictionary(tokens)\n",
    "dictionary_LDA.filter_extremes(no_below=3)\n",
    "corpus = [dictionary_LDA.doc2bow(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coherence(model, texts, dictionary):\n",
    "    coherence_model = CoherenceModel(\n",
    "        model=model, \n",
    "        texts=texts, \n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    return coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes several minutes to run. We have pickled the output.\n",
    "\n",
    "```python\n",
    "def get_metrics(texts, dictionary):\n",
    "    metrics_list = {\n",
    "        'n': [],\n",
    "        'mean_jaccard': [],\n",
    "        'coherence': []        \n",
    "    }\n",
    "    for n in tqdm(range(2,31)):\n",
    "        model = get_model(n)\n",
    "        topics = get_topics(model)\n",
    "        metrics_list['n'].append(n)\n",
    "        metrics_list['mean_jaccard'].append(mean_jaccard_similarity(topics)),\n",
    "        metrics_list['coherence'].append(get_coherence(model, texts, dictionary))\n",
    "    return metrics_list\n",
    "\n",
    "metrics_list = get_metrics(tokens, dictionary_LDA)\n",
    "with open('../model/metrics.pkl', mode='wb') as file:\n",
    "    pickle.dump(metrics_list, file)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/metrics.pkl', mode='rb') as file:\n",
    "    metrics_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    data_frame = metrics_df,\n",
    "    x = 'n',\n",
    "    y = ['mean_jaccard', 'coherence'],\n",
    "    title = 'latent dirichlet allocation topic number selection'.title(),\n",
    "    labels = {\n",
    "        'n': 'Number of Topics',\n",
    "        'variable': 'Metric'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot above, we select 24 topics for our model. It might be advisable to investigate models with more than 30 topics as both coherence and mean Jaccard similarity are still improving slowly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JobDash",
   "language": "python",
   "name": "jobdash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
