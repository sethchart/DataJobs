{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from JobsDb import JobsDb\n",
    "db = JobsDb()\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Psychiatrist (Per Diem) - #201222-4667HD</td>\n",
       "      <td>https://www.careerjet.com/jobad/us61b2e1c18a4d...</td>\n",
       "      <td>\\n  \\n    shall strive to be a global leader i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Professor of Osteopathic Manipulative Medicine</td>\n",
       "      <td>https://www.careerjet.com/jobad/us0f769e5a939c...</td>\n",
       "      <td>\\nPosition Details  Position Title Professor o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amazon Warehouse Assistant - Immediately Hiring</td>\n",
       "      <td>https://www.careerjet.com/jobad/usba95a3670331...</td>\n",
       "      <td>\\n  \\n    Hourly pay rate: $15.00 *The base pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Non-QM Underwriter</td>\n",
       "      <td>https://www.careerjet.com/jobad/usb59eda9438ed...</td>\n",
       "      <td>\\nJob Description  We looking to add an experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>project manager, accounting systems</td>\n",
       "      <td>https://www.careerjet.com/jobad/us71cfd31d23d6...</td>\n",
       "      <td>\\njob description  job summary:  Project Manag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            title  \\\n",
       "0   1         Psychiatrist (Per Diem) - #201222-4667HD   \n",
       "1   2   Professor of Osteopathic Manipulative Medicine   \n",
       "2   3  Amazon Warehouse Assistant - Immediately Hiring   \n",
       "3   4                               Non-QM Underwriter   \n",
       "4   5              project manager, accounting systems   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.careerjet.com/jobad/us61b2e1c18a4d...   \n",
       "1  https://www.careerjet.com/jobad/us0f769e5a939c...   \n",
       "2  https://www.careerjet.com/jobad/usba95a3670331...   \n",
       "3  https://www.careerjet.com/jobad/usb59eda9438ed...   \n",
       "4  https://www.careerjet.com/jobad/us71cfd31d23d6...   \n",
       "\n",
       "                                         description  \n",
       "0  \\n  \\n    shall strive to be a global leader i...  \n",
       "1  \\nPosition Details  Position Title Professor o...  \n",
       "2  \\n  \\n    Hourly pay rate: $15.00 *The base pa...  \n",
       "3  \\nJob Description  We looking to add an experi...  \n",
       "4  \\njob description  job summary:  Project Manag...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = db.load_table_as_df('jobs')\n",
    "db.close()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['title'].apply(lambda x: 'data' in x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract feature and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['target']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(list(df['description']))\n",
    "list_tokenized_descriptions = tokenizer.texts_to_sequences(df['description'])\n",
    "X_t = sequence.pad_sequences(list_tokenized_descriptions, maxlen=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "model.add(Embedding(20000, embedding_size))\n",
    "model.add(LSTM(25, return_sequences=True))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 25)          15400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 2,576,802\n",
      "Trainable params: 2,576,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "539/539 [==============================] - 329s 610ms/step - loss: 0.1329 - accuracy: 0.9488 - val_loss: 0.0085 - val_accuracy: 0.9979\n",
      "Epoch 2/3\n",
      "539/539 [==============================] - 354s 657ms/step - loss: 0.0291 - accuracy: 0.9937 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
      "Epoch 3/3\n",
      "539/539 [==============================] - 314s 582ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.0202 - val_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d6c697908>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, epochs=3, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/schart/anaconda3/envs/JobDash/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ../model/baseline/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../model/baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('../model/baseline')\n",
    "model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict classification on an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    6,    6,\n",
       "         44,   57,  160,   42,   54,   42,  661, 1051,  113,   57,  182,\n",
       "        636,  428, 1074, 1070, 1071,  198,  696, 1023,  519, 1067,   50,\n",
       "        158,  171,   31,  147,   23,  549,  658,  441,    8,  189,  431,\n",
       "       1075,   43,  892,  942,  387,   40,  318,  189,   17,   27,  206,\n",
       "         32,    2,  315,   15,  365,   88,  159,  426,  294,    2,    3,\n",
       "        480,    5,   34,   77,  165,  240,   50, 1076,  167,   40,    1,\n",
       "        402,   54,    5,    4,  328,   25,   29,  470, 1024,    4,  995,\n",
       "       1026,  487,    3,   25,   18,  448,  461, 1040,   11, 1072, 1077,\n",
       "        218,    2,  424,    3,   54,   42,  114,    1,   93,   29,   30,\n",
       "         21,  195,   10,   13,  523,  263,   10,  478,  127,  225,   71,\n",
       "          4,  676,  201,  591,    1,  662,  654,  620,  267,   10,  403,\n",
       "         98,  291,    8,  148,  129,   73,  174,  777,  968,   11,  140,\n",
       "          3,  569,   17, 1078,  973,  253,   25,  338,  220,   16,   51,\n",
       "        613,    4,  269,    1,  388,    5,   22,  263,   30,  225,  835,\n",
       "          1, 1073,  621,  530,  174,  131,   10,   19,  220,   16,  205,\n",
       "          2,   68,   33,  191,  113,  394,  347,    2,  149,   22,  367,\n",
       "         44,  183,   17,  991,   17,  547,  409,  173,  515,   11,  203,\n",
       "         21,   12,   58,  135,  242,  629,  334,  322,  570,  326,   14,\n",
       "          3,   50,  134,    1,  600,   63,  242,  381,  172,  335,   49,\n",
       "        261,   57,   57,   57,  359,   96,   16,  170,   28,   11,  577,\n",
       "          8,   35,    2,  483,    1,  631,  508,   10,  231,  601,  220,\n",
       "        161,   51,  261,   43,   49,   57,   13,   82,  580,    4,  358,\n",
       "        474,    1,  522,  156,  267,  117,   13,   21,   10,   40,  135,\n",
       "         57,   33,    4,  334,  322,  570,  326,    2,  242,  629,   40,\n",
       "        303,   13,  993,   14,  897,   44,  693,   57,   13,   82,   68,\n",
       "         22,  113,    2,  149,    4,   44,   29,  412,   10,   13,  250,\n",
       "         59,  126,  314,  427,   11,  235,  373,  185,  253,    2,  536,\n",
       "        191,  113,   40,   18,  232,    2,    4,  227,    1,  336,  331,\n",
       "         40,   18,   27,  124,   67,  138,    1,  349,   97,  457,   14,\n",
       "          3,  256,    5,  132,  111,  137,   74,   74,  143,  142,  136,\n",
       "         76,  139,   52,  100,  196,   11,   45,  386,   76,   52,   10,\n",
       "        249,    8,  340,   77,  320,  180,    2,  363,   27,  300,  151,\n",
       "        479,  657,  612,  269,  921,  147, 5856,  519, 5974,    6,    6,\n",
       "          6,    6,   40,    6,    6], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = df['description'][2000]\n",
    "embedded_doc = X_t[2000]\n",
    "embedded_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165128],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5883486 , 0.41165137],\n",
       "       [0.5682302 , 0.43176982],\n",
       "       [0.5682302 , 0.43176982],\n",
       "       [0.825776  , 0.174224  ],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.40358308, 0.59641695],\n",
       "       [0.63389605, 0.36610395],\n",
       "       [0.43695533, 0.56304467],\n",
       "       [0.63389605, 0.36610395],\n",
       "       [0.71320546, 0.2867945 ],\n",
       "       [0.53344995, 0.4665501 ],\n",
       "       [0.8153328 , 0.18466721],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.6281158 , 0.37188423],\n",
       "       [0.8840262 , 0.11597377],\n",
       "       [0.90685695, 0.09314305],\n",
       "       [0.4950679 , 0.50493205],\n",
       "       [0.52639884, 0.47360116],\n",
       "       [0.6753075 , 0.32469243],\n",
       "       [0.71279454, 0.28720546],\n",
       "       [0.4395078 , 0.5604922 ],\n",
       "       [0.68542   , 0.3145801 ],\n",
       "       [0.6812489 , 0.31875113],\n",
       "       [0.5497811 , 0.45021892],\n",
       "       [0.5489633 , 0.45103672],\n",
       "       [0.48181653, 0.51818347],\n",
       "       [0.85986227, 0.1401377 ],\n",
       "       [0.7864836 , 0.21351638],\n",
       "       [0.5583956 , 0.4416044 ],\n",
       "       [0.53651077, 0.46348923],\n",
       "       [0.32370356, 0.6762965 ],\n",
       "       [0.768951  , 0.23104905],\n",
       "       [0.59503603, 0.40496397],\n",
       "       [0.58735406, 0.4126459 ],\n",
       "       [0.6091265 , 0.3908735 ],\n",
       "       [0.35121912, 0.6487809 ],\n",
       "       [0.81873035, 0.18126962],\n",
       "       [0.67780995, 0.32219002],\n",
       "       [0.3112469 , 0.6887531 ],\n",
       "       [0.6755177 , 0.32448238],\n",
       "       [0.49726298, 0.50273705],\n",
       "       [0.7580037 , 0.24199627],\n",
       "       [0.903353  , 0.09664705],\n",
       "       [0.6091265 , 0.3908735 ],\n",
       "       [0.42013806, 0.57986194],\n",
       "       [0.62835366, 0.3716463 ],\n",
       "       [0.18469289, 0.8153071 ],\n",
       "       [0.27056536, 0.72943467],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.2679959 , 0.73200417],\n",
       "       [0.34561458, 0.6543854 ],\n",
       "       [0.42824572, 0.5717543 ],\n",
       "       [0.41323453, 0.58676547],\n",
       "       [0.23611613, 0.7638839 ],\n",
       "       [0.5299823 , 0.47001764],\n",
       "       [0.49630073, 0.50369924],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.45731682, 0.5426832 ],\n",
       "       [0.76430833, 0.23569171],\n",
       "       [0.5967734 , 0.4032266 ],\n",
       "       [0.21495238, 0.78504765],\n",
       "       [0.63612133, 0.36387867],\n",
       "       [0.38782835, 0.61217165],\n",
       "       [0.40343568, 0.59656435],\n",
       "       [0.5489633 , 0.45103672],\n",
       "       [0.7080542 , 0.29194584],\n",
       "       [0.5954749 , 0.4045251 ],\n",
       "       [0.7580037 , 0.24199627],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.79764426, 0.20235571],\n",
       "       [0.43695533, 0.56304467],\n",
       "       [0.5967734 , 0.4032266 ],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.48232514, 0.5176748 ],\n",
       "       [0.4753843 , 0.52461576],\n",
       "       [0.38306746, 0.6169325 ],\n",
       "       [0.48730844, 0.5126915 ],\n",
       "       [0.8679541 , 0.13204594],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.32115218, 0.6788478 ],\n",
       "       [0.8468248 , 0.15317516],\n",
       "       [0.3010408 , 0.69895923],\n",
       "       [0.45731682, 0.5426832 ],\n",
       "       [0.4753843 , 0.52461576],\n",
       "       [0.5870012 , 0.41299877],\n",
       "       [0.95002043, 0.04997955],\n",
       "       [0.92092365, 0.07907629],\n",
       "       [0.8798433 , 0.12015674],\n",
       "       [0.55789906, 0.44210094],\n",
       "       [0.86873704, 0.13126302],\n",
       "       [0.8460476 , 0.15395243],\n",
       "       [0.6756742 , 0.32432577],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.5443439 , 0.45565617],\n",
       "       [0.45731682, 0.5426832 ],\n",
       "       [0.43695533, 0.56304467],\n",
       "       [0.63389605, 0.36610395],\n",
       "       [0.6931998 , 0.30680016],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.29434592, 0.7056541 ],\n",
       "       [0.38306746, 0.6169325 ],\n",
       "       [0.41802132, 0.5819787 ],\n",
       "       [0.36211568, 0.63788426],\n",
       "       [0.2913952 , 0.7086048 ],\n",
       "       [0.51141495, 0.48858514],\n",
       "       [0.5926671 , 0.4073329 ],\n",
       "       [0.08605023, 0.9139497 ],\n",
       "       [0.65438384, 0.3456161 ],\n",
       "       [0.51141495, 0.48858514],\n",
       "       [0.178978  , 0.82102203],\n",
       "       [0.3991411 , 0.6008589 ],\n",
       "       [0.48925883, 0.5107412 ],\n",
       "       [0.65756464, 0.34243536],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.7230213 , 0.27697864],\n",
       "       [0.7006381 , 0.29936185],\n",
       "       [0.8183856 , 0.18161438],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.4355045 , 0.5644955 ],\n",
       "       [0.32518497, 0.674815  ],\n",
       "       [0.7231002 , 0.2768998 ],\n",
       "       [0.52382094, 0.47617906],\n",
       "       [0.51141495, 0.48858514],\n",
       "       [0.5026316 , 0.49736843],\n",
       "       [0.50467837, 0.49532166],\n",
       "       [0.5899923 , 0.41000775],\n",
       "       [0.58735406, 0.41264597],\n",
       "       [0.3850219 , 0.6149781 ],\n",
       "       [0.673228  , 0.32677206],\n",
       "       [0.47143203, 0.528568  ],\n",
       "       [0.49163747, 0.5083625 ],\n",
       "       [0.4741113 , 0.52588874],\n",
       "       [0.46701583, 0.5329842 ],\n",
       "       [0.55789906, 0.44210094],\n",
       "       [0.5309573 , 0.4690427 ],\n",
       "       [0.45731682, 0.5426832 ],\n",
       "       [0.6544232 , 0.34557682],\n",
       "       [0.42013806, 0.57986194],\n",
       "       [0.7981991 , 0.20180096],\n",
       "       [0.739008  , 0.26099193],\n",
       "       [0.57706565, 0.42293438],\n",
       "       [0.4753843 , 0.52461576],\n",
       "       [0.5964372 , 0.4035628 ],\n",
       "       [0.9983658 , 0.00163422],\n",
       "       [0.362925  , 0.63707495],\n",
       "       [0.5525854 , 0.44741452],\n",
       "       [0.806713  , 0.19328699],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.5589497 , 0.44105023],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.77529156, 0.22470851],\n",
       "       [0.5967734 , 0.4032266 ],\n",
       "       [0.46800804, 0.5319919 ],\n",
       "       [0.65438384, 0.3456161 ],\n",
       "       [0.41802132, 0.5819787 ],\n",
       "       [0.48925883, 0.5107412 ],\n",
       "       [0.90265155, 0.09734849],\n",
       "       [0.62290716, 0.37709284],\n",
       "       [0.9700751 , 0.02992488],\n",
       "       [0.6432798 , 0.35672015],\n",
       "       [0.9624377 , 0.0375623 ],\n",
       "       [0.49163747, 0.5083625 ],\n",
       "       [0.85685414, 0.14314583],\n",
       "       [0.51141495, 0.48858514],\n",
       "       [0.8081941 , 0.19180587],\n",
       "       [0.9983658 , 0.00163422],\n",
       "       [0.362925  , 0.63707495],\n",
       "       [0.43756405, 0.562436  ],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.9118952 , 0.08810483],\n",
       "       [0.32332656, 0.6766734 ],\n",
       "       [0.7650059 , 0.23499404],\n",
       "       [0.8153328 , 0.18466721],\n",
       "       [0.5080346 , 0.49196538],\n",
       "       [0.4070474 , 0.5929526 ],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.53773284, 0.46226716],\n",
       "       [0.46800804, 0.5319919 ],\n",
       "       [0.324117  , 0.67588305],\n",
       "       [0.825776  , 0.174224  ],\n",
       "       [0.42375195, 0.57624805],\n",
       "       [0.42013806, 0.5798619 ],\n",
       "       [0.50582135, 0.49417868],\n",
       "       [0.42013806, 0.57986194],\n",
       "       [0.4104175 , 0.58958256],\n",
       "       [0.71190506, 0.2880949 ],\n",
       "       [0.57042676, 0.4295733 ],\n",
       "       [0.45310247, 0.54689753],\n",
       "       [0.55789906, 0.44210094],\n",
       "       [0.2644049 , 0.7355951 ],\n",
       "       [0.36211574, 0.63788426],\n",
       "       [0.57338375, 0.42661622],\n",
       "       [0.58681446, 0.41318548],\n",
       "       [0.457073  , 0.54292697],\n",
       "       [0.3412456 , 0.6587544 ],\n",
       "       [0.61967003, 0.38033006],\n",
       "       [0.6151541 , 0.38484588],\n",
       "       [0.6684    , 0.33160004],\n",
       "       [0.25255054, 0.74744946],\n",
       "       [0.458378  , 0.5416221 ],\n",
       "       [0.36381987, 0.6361801 ],\n",
       "       [0.45731682, 0.5426832 ],\n",
       "       [0.5489633 , 0.45103672],\n",
       "       [0.74800485, 0.25199518],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.4264158 , 0.57358426],\n",
       "       [0.43329945, 0.5667006 ],\n",
       "       [0.3412456 , 0.6587544 ],\n",
       "       [0.64025646, 0.3597435 ],\n",
       "       [0.531478  , 0.468522  ],\n",
       "       [0.35264936, 0.64735067],\n",
       "       [0.28777522, 0.7122247 ],\n",
       "       [0.33743533, 0.6625647 ],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.19755203, 0.802448  ],\n",
       "       [0.44772694, 0.55227315],\n",
       "       [0.362925  , 0.63707495],\n",
       "       [0.61749554, 0.38250443],\n",
       "       [0.5028591 , 0.4971409 ],\n",
       "       [0.55789906, 0.442101  ],\n",
       "       [0.5900517 , 0.40994835],\n",
       "       [0.58735406, 0.4126459 ],\n",
       "       [0.7183474 , 0.2816526 ],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.4073394 , 0.5926606 ],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.44608513, 0.5539149 ],\n",
       "       [0.74504197, 0.25495806],\n",
       "       [0.51141495, 0.4885851 ],\n",
       "       [0.45541552, 0.5445845 ],\n",
       "       [0.31948373, 0.68051624],\n",
       "       [0.9983658 , 0.00163422],\n",
       "       [0.43909526, 0.5609047 ],\n",
       "       [0.5525854 , 0.44741452],\n",
       "       [0.33743533, 0.6625647 ],\n",
       "       [0.67780995, 0.32219002],\n",
       "       [0.28777522, 0.7122248 ],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.5926671 , 0.4073329 ],\n",
       "       [0.5355416 , 0.46445838],\n",
       "       [0.6533911 , 0.34660888],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.7327826 , 0.26721737],\n",
       "       [0.88584787, 0.11415216],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.37934193, 0.62065816],\n",
       "       [0.45520195, 0.5447981 ],\n",
       "       [0.52382094, 0.47617906],\n",
       "       [0.7432624 , 0.2567376 ],\n",
       "       [0.5926671 , 0.4073329 ],\n",
       "       [0.36211568, 0.63788426],\n",
       "       [0.51141495, 0.4885851 ],\n",
       "       [0.7580037 , 0.24199627],\n",
       "       [0.457073  , 0.54292697],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.32332656, 0.6766734 ],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.6151541 , 0.38484588],\n",
       "       [0.6684    , 0.33160004],\n",
       "       [0.25255054, 0.74744946],\n",
       "       [0.458378  , 0.5416221 ],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.3412456 , 0.6587544 ],\n",
       "       [0.61967003, 0.38033006],\n",
       "       [0.7580037 , 0.24199627],\n",
       "       [0.5109911 , 0.48900893],\n",
       "       [0.5926671 , 0.4073329 ],\n",
       "       [0.40801913, 0.59198093],\n",
       "       [0.36381987, 0.6361801 ],\n",
       "       [0.28797817, 0.7120219 ],\n",
       "       [0.825776  , 0.174224  ],\n",
       "       [0.19128385, 0.8087162 ],\n",
       "       [0.96188205, 0.03811799],\n",
       "       [0.5926671 , 0.4073329 ],\n",
       "       [0.5355416 , 0.46445838],\n",
       "       [0.9118952 , 0.08810483],\n",
       "       [0.46800804, 0.5319919 ],\n",
       "       [0.8153328 , 0.18466721],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.53773284, 0.46226716],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.825776  , 0.174224  ],\n",
       "       [0.38306746, 0.6169325 ],\n",
       "       [0.62564695, 0.37435302],\n",
       "       [0.51141495, 0.4885851 ],\n",
       "       [0.5926671 , 0.4073329 ],\n",
       "       [0.8400884 , 0.15991154],\n",
       "       [0.5443848 , 0.4556152 ],\n",
       "       [0.20975383, 0.7902461 ],\n",
       "       [0.44812244, 0.5518776 ],\n",
       "       [0.42220834, 0.57779163],\n",
       "       [0.55789906, 0.44210097],\n",
       "       [0.5284633 , 0.47153673],\n",
       "       [0.56963235, 0.43036765],\n",
       "       [0.44690043, 0.5530996 ],\n",
       "       [0.57706565, 0.42293438],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.20333605, 0.7966639 ],\n",
       "       [0.7650059 , 0.23499404],\n",
       "       [0.8153328 , 0.18466721],\n",
       "       [0.7580037 , 0.24199627],\n",
       "       [0.5870012 , 0.41299877],\n",
       "       [0.6887619 , 0.3112381 ],\n",
       "       [0.7193344 , 0.28066558],\n",
       "       [0.56423104, 0.435769  ],\n",
       "       [0.07341836, 0.9265817 ],\n",
       "       [0.6229072 , 0.37709278],\n",
       "       [0.6610898 , 0.33891025],\n",
       "       [0.13396236, 0.86603767],\n",
       "       [0.7580037 , 0.24199627],\n",
       "       [0.5870012 , 0.41299877],\n",
       "       [0.62835366, 0.3716463 ],\n",
       "       [0.5853602 , 0.4146398 ],\n",
       "       [0.6861735 , 0.3138265 ],\n",
       "       [0.5935856 , 0.40641436],\n",
       "       [0.6229072 , 0.37709284],\n",
       "       [0.14673147, 0.8532685 ],\n",
       "       [0.40289775, 0.5971023 ],\n",
       "       [0.7050227 , 0.2949773 ],\n",
       "       [0.36381987, 0.6361801 ],\n",
       "       [0.45731682, 0.5426832 ],\n",
       "       [0.370629  , 0.629371  ],\n",
       "       [0.5967734 , 0.4032266 ],\n",
       "       [0.5897743 , 0.41022563],\n",
       "       [0.48893175, 0.5110683 ],\n",
       "       [0.33759266, 0.6624073 ],\n",
       "       [0.7123932 , 0.28760678],\n",
       "       [0.7123932 , 0.28760678],\n",
       "       [0.59873307, 0.4012669 ],\n",
       "       [0.46208003, 0.53791994],\n",
       "       [0.77162737, 0.22837262],\n",
       "       [0.5219587 , 0.4780413 ],\n",
       "       [0.35719478, 0.6428052 ],\n",
       "       [0.3602753 , 0.63972473],\n",
       "       [0.34932065, 0.65067935],\n",
       "       [0.45894194, 0.541058  ],\n",
       "       [0.55789906, 0.44210094],\n",
       "       [0.56127584, 0.43872416],\n",
       "       [0.44444513, 0.55555487],\n",
       "       [0.5219587 , 0.4780413 ],\n",
       "       [0.3602753 , 0.63972473],\n",
       "       [0.51141495, 0.48858514],\n",
       "       [0.7010279 , 0.29897213],\n",
       "       [0.58735406, 0.4126459 ],\n",
       "       [0.70170534, 0.2982947 ],\n",
       "       [0.63612133, 0.36387867],\n",
       "       [0.38642365, 0.6135763 ],\n",
       "       [0.69437873, 0.3056213 ],\n",
       "       [0.7193344 , 0.28066564],\n",
       "       [0.5171889 , 0.48281103],\n",
       "       [0.62835366, 0.3716463 ],\n",
       "       [0.46485886, 0.5351411 ],\n",
       "       [0.22714318, 0.77285683],\n",
       "       [0.86773765, 0.1322624 ],\n",
       "       [0.9132901 , 0.08670988],\n",
       "       [0.6945575 , 0.30544248],\n",
       "       [0.5589497 , 0.44105023],\n",
       "       [0.7321632 , 0.26783687],\n",
       "       [0.5583956 , 0.4416044 ],\n",
       "       [0.5445439 , 0.45545608],\n",
       "       [0.6812489 , 0.31875113],\n",
       "       [0.4879923 , 0.5120077 ],\n",
       "       [0.5682302 , 0.43176982],\n",
       "       [0.5682302 , 0.43176982],\n",
       "       [0.5682302 , 0.43176982],\n",
       "       [0.5682302 , 0.43176982],\n",
       "       [0.7580037 , 0.24199627],\n",
       "       [0.5682302 , 0.43176982],\n",
       "       [0.5682302 , 0.43176982]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(embedded_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2944bd67f131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JobDash/lib/python3.6/site-packages/eli5/lime/lime.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, doc, predict_proba)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             samples, sims = self.sampler.sample_near(\n\u001b[1;32m    245\u001b[0m                 \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JobDash/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \"\"\"\n\u001b[1;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JobDash/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JobDash/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JobDash/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/JobDash/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(embedded_doc, model.predict_proba)\n",
    "te.show_prediction(target_names=model.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JobDash",
   "language": "python",
   "name": "jobdash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
