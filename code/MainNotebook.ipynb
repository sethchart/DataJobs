{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Job Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from plotly import express as px\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def make_wordcloud(text):\n",
    "    wordcloud = WordCloud(background_color='white', width=3200, height=2400)\n",
    "    wordcloud.generate(text)\n",
    "    fig = plt.figure(figsize = (16,12))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    return fig\n",
    "\n",
    "# Inspecting modules\n",
    "import inspect\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_object(obj):\n",
    "    source = inspect.getsource(obj)\n",
    "    wrapped_source = f'```python\\n{source}\\n```'\n",
    "    markdown_source = Markdown(wrapped_source)\n",
    "    display(markdown_source)\n",
    "    \n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Timing \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Processed data storage\n",
    "import pickle\n",
    "\n",
    "# Build corpus\n",
    "from gensim import corpora\n",
    "\n",
    "# Latent Dirichlet Allocation\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# K-means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Clustering Evaluation\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score, confusion_matrix\n",
    "\n",
    "# Word count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Naive Bayes'\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seth Chart, PhD\n",
    "\n",
    "Data Scientist & Mathematician\n",
    "\n",
    "Seeking opportunities in Data Science\n",
    " * Email: [seth.chart@protonmail.com](mailto:seth.chart@protonmail.com)\n",
    " * Phone: [443.303.7114](tel:4433037114)\n",
    " * [Resume](https://sethchart.com/resume-sethchart.pdf)\n",
    " * [GitHub](https://github.com/sethchart)\n",
    " * [LinkedIn](https://www.linkedin.com/in/sethchart)\n",
    " * [Website](https://sethchart.com)\n",
    " * [Twitter](https://www.linkedin.com/in/sethchart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job market for the data industry can be difficult to navigate because there are a plethora of job titles and the relationship between titles and roles is often not well defined.\n",
    "Two identical roles may have completely different titles.\n",
    "Two substantially different roles may have the same title.\n",
    "This limits the usability of job titles as a means to succinctly communicate about data industry jobs.\n",
    "This project will address the issue by directly analyzing full job descriptions from a corpus of job postings to provide three main deliverables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * First, from the language used in job descriptions (without titles), identify clusters of similar jobs based on their roles and responsibilities.\n",
    " * Second, a tool for classifying a provided job description according to our scheme.\n",
    " * Third, a comparison between our classification scheme and existing job titles ability to distinguish between roles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently two of the most recognizable job posting sites, LinkedIn and Indeed, have closed their job posting APIs and taken steps to discourage web scraping. This means that our preferred data sources were not available. \n",
    "\n",
    "We found that [careerjet.com](http://careerjet.com) has an public API and a fairly simple page structure for job posting. The official API [page](https://www.careerjet.com/partners/api/) for careerjet provides a python API package. Unfortunately, the official python package is not functional. There is an unofficial fork of the package that is functional that can be found [here](https://github.com/davebulaval/careerjet-api). \n",
    "\n",
    "The careerjet API is designed as a method for serving ads and tracks visits to careerjet job postings. For this reason, there are fairly restrictive rate limits for retrieving postings through the API. These limitations are not clearly documented, but they rendered the API unusable for large scale data collection.\n",
    "\n",
    "After discovering that the careerjet API would not be usable for data collection we investigated the possibility of scraping job postings by exploiting the page number url parameter to iterate over search result pages, scrape posting results from each result listing, then scrape each result url. However, after experimentation we discovered that the site only surfaces one hundred pages of search results with twenty postings per page.\n",
    "\n",
    "Finally, we determined that a by initiating a scraping process on the post listed first in the careerjet search results and using Selenium to advance to the next search result, we were able to access up to ten thousand job postings in a scraping session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mining Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our data mining process was to obtain a reasonably large corpus of job postings consisting of a job title and a job description within the data job sector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Initiate a search for jobs postings located in the United States containing the keyword `data`. \n",
    " 2. Traverse and scrape job postings using the Selenium webdriver.\n",
    " 3. Store scraped posts in a SQLite database for further analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work-flow below applies to both job descriptions and job titles. This process seeks to distill the raw text to a list of unique and independent tokens of information.\n",
    " \n",
    " 1. Lowercase and remove newline characters.\n",
    " 2. Tokenize documents into sentences.\n",
    " 3. Tokenize sentences into words.\n",
    " 4. Tag words with parts-of-speech tags.\n",
    " 5. Lemmatize words based on parts-of-speech tags.\n",
    " 6. Remove stopwords and special characters.\n",
    " 7. Group common bigrams and trigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially we wish to model two activities related to searching for a job. First, reading full job descriptions to determine the relevant skills and requirements, thereby classifying the job. Second, skimming over job titles to classify jobs. \n",
    "\n",
    "The goal of a job listing should be to efficiently communicate the requirements of the job so that employers and job seekers can easily match. Job titles are essentially a summary of the full job description which should allow a job seeker to quickly reject postings that are not relevant for further review. When the job title is not predictive of the requirements of the job, a job seeker must review full job descriptions to correctly reject job postings or accept a high false negative rate for title skimming. Either approach leads to reduced efficiency in the job seeking process. \n",
    "\n",
    "Our first model will produce a data supported summary of a job description, which should be as easy to parse as a job title, but more predictive of the job description.\n",
    "\n",
    "Our second model will try to simulate the process of classifying a job by reading the job title alone. From this model, we wish to estimate the false negative rate for this method of rejecting a job posting for further review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unsupervised Learning on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having distilled job descriptions to token lists we wish to derive meaningful representations of the job descriptions, which lend themselves to succinct classification of jobs. To this end we propose the following work-flow.\n",
    " \n",
    " 1. Convert token lists to bag-of-words representation.\n",
    " 2. Train a Latent Dirichlet Allocation model on the bag-of-words representations to extract a latent topics representation of the job descriptions. \n",
    " 3. Train a K-Means clustering model on the latent topics representations to identify clusters of similar job descriptions.\n",
    " \n",
    " The labeling of job descriptions with their corresponding cluster label provides our first deliverable.\n",
    " \n",
    " Having trained both LDA and K-Means models on the collected data, we can feed an unseen job description through our model pipeline and assign a cluster label. This provides our second deliverable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Supervised Learning on Job Titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having classified jobs to the best of our abilities using the full job description, we now wish to determine how effectively we are able to predict the cluster label of the job using only the job title. We propose the following work-flow.\n",
    "\n",
    " 1. Convert job title token lists to token count vectors.\n",
    " 2. Train a Multinomial Naive Bayes' taking job title token count vectors as inputs to predict job cluster labels. This simulates a job seeker classifying a job based on the occurrence of key words or phrases in the job title. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will provide a publicly available interface, which will allow the end user to classify raw job description text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to produce our deliverables, we will needed a sizable corpus of data industry job descriptions.\n",
    "We were able to obtain a corpus of approximately 9,485 job descriptions paired with their assigned job titles.\n",
    "The descriptions from this corpus will serve as our data for deliverables one and two.\n",
    "We will use the job titles from this corpus as data for deliverable three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection is executed by the `scrape` script, which depends on the `careerjet` and `JobsDb` modules. Essentially, the script bellow executes the following steps.\n",
    " 1. Instantiate a `JobsDb` object, which provides methods for writing records to the database.\n",
    " 2. Instantiate a `Scraper` object which opens a chrome browser and navigates to the first careerjet.com job posting page.\n",
    " 3. Scrape page contents.\n",
    " 4. Write record to database.\n",
    " 5. Advance to next page and return to Step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `scrape` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrape\n",
    "display_object(scrape.main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `careeerjet` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import careerjet\n",
    "display_object(careerjet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `JobsDb` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import JobsDb\n",
    "display_object(JobsDb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We executed two runs of the `scrape` script. The first run did not include `data` as a search term, so it retrieved a sampling of the full job market. The second run included the search term `data`, so it retrieved a sampling of the data industry job market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we leverage the JobsDb module to load our full data set from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = JobsDb.JobsDb()\n",
    "df = db.load_table_as_df('jobs')\n",
    "db.close()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f' Our database currenlty contains {len(df)} job postings scraped from careerjet.com.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Records Containing `data` Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT * from jobs\n",
    "WHERE title LIKE '%data%'\n",
    "OR description LIKE '%data%';\n",
    "\"\"\"\n",
    "db = JobsDb.JobsDb()\n",
    "data = db.load_query_as_df(query)\n",
    "db.close()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f' Our database currenlty contains {len(data)} job postings scraped from careerjet.com with the keyword `data`.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we explore the distribution of lengths, measured by the number of characters for job titles and job descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_length = data['title'].apply(len)\n",
    "median_title_length =title_length.median()\n",
    "fig = px.histogram(\n",
    "    title_length,\n",
    "    title = f'Distribution of Job Title Lengths (Medain {median_title_length})',\n",
    "    labels = {\n",
    "        'value': 'Title Length (characters)',\n",
    "    },\n",
    "    nbins = 45,\n",
    ")\n",
    "fig.layout.update(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_length = data['description'].apply(len)\n",
    "median_description_length = description_length.median()\n",
    "fig = px.histogram(\n",
    "    description_length,\n",
    "    title = f'Distribution of Job Description Lengths (Medain {median_description_length})',\n",
    "    labels = {\n",
    "        'value': 'Description Length (characters)',\n",
    "    },\n",
    "    nbins = 45,\n",
    ")\n",
    "fig.layout.update(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we check data types and ensure that there are no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three columns from our dataset are formatted as strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we take an in depth look at the data preparation process. All data processing is handled by the `DataProcessor` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import DataProcessor\n",
    "display_object(DataProcessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposed of this analysis we are only interested in job postings related to the data industry. For this reason we will only include postings the contain the keyword `data ` in either the job title or the job description. We have already extracted this data from the database [here](#Records-Containing-data-Keyword). For your convenience we reproduce the required code below.\n",
    "```python\n",
    "query = \"\"\"\n",
    "SELECT * from jobs\n",
    "WHERE title LIKE '%data%'\n",
    "OR description LIKE '%data%';\n",
    "\"\"\"\n",
    "db = JobsDb.JobsDb()\n",
    "data = db.load_query_as_df(query)\n",
    "db.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly demonstrate the steps in our data cleaning pipeline, we will select a single example record and apply each step in sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting an Example Job Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we select a job posting at random from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_index = np.random.choice(len(data))\n",
    "job_post = data.iloc[example_index]\n",
    "title = job_post['title']\n",
    "description = job_post['description']\n",
    "print(f'{title}\\n\\n{description}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Raw description word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = make_wordcloud(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `doc_tokenizer` method first splits a document into a list of sentences, then splits each sentence into a list of words. This method depends on the following methods:\n",
    " * `sent_tokenize` and `word_tokenize` from `nltk.tokenize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `doc_tokenizer` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.doc_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_tokens = DataProcessor.doc_tokenizer(title)\n",
    "description_tokens = DataProcessor.doc_tokenizer(description)\n",
    "print(f'{title_tokens}\\n\\n{description_tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `doc_pos_tagger` method parses the tokenized text from the step above and applies a wordnet part of speech tag. This method depends on the following methods:\n",
    " * `sentence_pos_tagger` and `get_wordnet_pos` from `DataProcessor`\n",
    " * `pos_tag` from `nltk`\n",
    " * `wordnet` from `nltk.corpus`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `doc_pos_tagger` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.doc_pos_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_pos_tags = DataProcessor.doc_pos_tagger(title_tokens)\n",
    "description_pos_tags = DataProcessor.doc_pos_tagger(description_tokens)\n",
    "print(f'{title_pos_tags}\\n\\n{description_pos_tags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `sentence_pos_tagger` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.sentence_pos_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `get_wordnet_pos` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.get_wordnet_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `doc_lemmatizer` method parses the POS tagged text and, where possible, replaces words with their [lemmas](https://en.wikipedia.org/wiki/Lemmatisation). This method depends on the following methods and classes:\n",
    " * `sentence_lemmatizer` and `tag_lemmatizer` from `DataProcessor`\n",
    " * `WordNetLemmatizer` from `nltk.stem.wordnet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `doc_lemmatizer` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.doc_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_lemmas = DataProcessor.doc_lemmatizer(title_pos_tags)\n",
    "description_lemmas = DataProcessor.doc_lemmatizer(description_pos_tags)\n",
    "print(f'{title_lemmas}\\n\\n{description_lemmas}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `sentence_lemmatizer` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.sentence_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `tag_lemmatizer` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.tag_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `doc_clean` method removes special characters and stopwords. It depends on the following methods.\n",
    " * `stopwords` from `nltk.corpus`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `doc_clean` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.doc_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_clean = DataProcessor.doc_clean(title_lemmas)\n",
    "description_clean = DataProcessor.doc_clean(description_lemmas)\n",
    "print(f'{title_clean}\\n\\n{description_clean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_clean_text = ' '.join(description_clean)\n",
    "fig = make_wordcloud(description_clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below we process the full data set using the `data_processor` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `data_processor` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.data_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data['title']\n",
    "titles_processed = DataProcessor.data_processor(tqdm(titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell takes several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = data['description']\n",
    "descriptions_processed = DataProcessor.data_processor(tqdm(descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Common Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having cleaned our data we wish to combine common phrases into bigrams, trigrams, and quadgrams. This helps to ensure that each token in our final representation of our text is an independent unit of information.\n",
    "\n",
    "The `data_combine_phrases` method uses the full corpus to detect common phrases and combine them into bigrams, trigrams, and quadgrams. when this method is run it saves a copy of the two required `Phrases` models to the `model` folder. This method depends on the following class.\n",
    " * `Phrases` from `gensim.models`\n",
    " \n",
    "Once `data_combine_phrases` has built a phrase model for the provided data, we can combine phrases for an unseen document.\n",
    "\n",
    "The `doc_combine_phrases` method will combine common phrases into $n$-grams for an unseen document. This method has the following dependencies.\n",
    " * `Phrases` from `gensim.models`\n",
    " * The model trained by `data_combine_phrases`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `data_combine_phrases` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.data_combine_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_phrases = DataProcessor.data_combine_phrases(tqdm(titles_processed), 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_phrases = DataProcessor.data_combine_phrases(tqdm(descriptions_processed), 'description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `doc_combine_phrases` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object(DataProcessor.doc_combine_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_grams = DataProcessor.doc_combine_phrases(title_clean, 'title')\n",
    "description_grams = DataProcessor.doc_combine_phrases(description_clean, 'description')\n",
    "print(f'{title_grams}\\n\\n{description_grams}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Description grams word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_grams_text = ' '.join(description_grams)\n",
    "fig = make_wordcloud(description_grams_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processed Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above. It takes around ten minutes in total to execute data cleaning and feature engineering on the full data set. For this reason it is useful to store our processed data for future use. Below we package our raw data with our processed data in a list of dictionaries and save the resulting object as a pickle file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining raw data and processed data for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_records = data.to_dict('records')\n",
    "for post, description_tokens, title_tokens in tqdm(zip(data_records, description_phrases, title_phrases)):\n",
    "    post['title_tokens'] = title_tokens\n",
    "    post['description_tokens'] = description_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the first record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_records[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving to pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below should only be run if the `processed_data` file needs to be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with open('../data/processed_data.pkl', mode='wb') as file:\n",
    "    pickle.dump(data_records, file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of a job posting is to communicate the responsibilities and requirements of a job to potential applicants. When a job seeker is viewing job postings, their goal is to identify jobs that are closely aligned with their skills efficiently. Both employers and job seekers benefit from postings that efficiently communicate the precise requirements of a job. The employer receives more relevant job applicants, which results in a more efficient hiring process. The job seeker is able to evaluate jobs effectively and invest time in applying to only those jobs that are relevant to their skills, which results in a more efficient job seeking process.\n",
    "\n",
    "The first step of the job seeking process is to evaluate large batches of job postings and identify relevant postings. In this phase, the greatest contributer to efficiency is the ability to rapidly reject irrelevant postings. The most consistently available information in a job posting is a job title and a job description. A fairly standard approach to reviewing a collection of job postings is to read the job titles, reject all of the postings with irrelevant job titles and then review the job descriptions for the remaining job posts. Because reviewing a job description can take substantially longer than reviewing a job title, it is not feasible to review all job descriptions. \n",
    "\n",
    "An issue arises with this strategy if job titles do not provide an accurate classification of the job that they describe. The primary issue being low accuracy in predicting the nature of a job from the job title. In the case of a false negative, the job seeker incorrectly classifies a job as irrelevant and discards it without further review, missing an opportunity to apply for a relevant job. In the case of a false positive, the job seeker carries an irrelevant job posting forward for further review, incurring an opportunity cost by wasting time that could have been used pursuing a relevant job.\n",
    "\n",
    "In this section, we take the view that a job description is a complete and correct representation of the job. Our first modeling task is to produce quantitative representation of the data contained in the job description. For this task, we have selected a Latent Dirichlet Allocation (LDA) model. This type of model assumes that every document (job description) in our corpus is created by selecting a mixture of topics (responsibilities and requirements) and then selecting words according to a distribution that is conditioned on the mixture of topics. This is a plausible model for job descriptions since the author of the job posting must describe a handful of requirements of the job, where each requirement will have a handful of distinguishing key words. \n",
    "\n",
    "A fitted LDA model produces a list of topics, each containing a list of top keywords. For any document, the model provides a probability vector indicating the mixture of topics that are present in the document. \n",
    "\n",
    "Because the list of topics are inferred from the corpus of documents, we must review the list of top keywords and identify the essential meaning of the topic. \n",
    "\n",
    "One of the hyper parameters of an LDA model is the number of topics to detect. It is important that we carefully select an appropriate number of topics. We want our topics to be coherent, which generally drives us toward more topics which capture smaller and more precise topics. On the other hand, we want our topic to be distinct, this generally drives us toward fewer topics. By balancing these two considerations, we will select an appropriate number of topics for our LDA model. \n",
    "\n",
    "Once we have a topic mixture representation of our job descriptions, we can cluster jobs into classes with similar mixtures of topics. For this task we will use a K-means clustering algorithm.\n",
    "\n",
    "We will need to tune the number of clusters for our K-means clustering to ensure that jobs are grouped into distinct and self similar classes. \n",
    "\n",
    "Finally, we will train a multinomial Naive Bayes' classifier on the job titles to predict the job class produced by LDA and K-means. The accuracy of this model provides an estimate of the accuracy of classifying jobs as relevant or not based on job title alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both LDA and K-means are unsupervised learning techniques, as such we will need to carefully tune hyper-parameters to ensure that these models are performing optimally. However, we do not have access to ground truth to test these models.\n",
    "\n",
    "For our Multinomial Naive Bayes' classifier, we will implement a train test split for model verification and use five-fold cross-validation to validate our selection of the number of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed_data.pkl', mode='rb') as file:\n",
    "    data_records = pickle.load(file)\n",
    "\n",
    "title_tokens = [record['title_tokens'] for record in data_records]\n",
    "description_tokens = [record['description_tokens'] for record in data_records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Dirichlet Allocation Topic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build dictionary and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9666/9666 [00:04<00:00, 2082.48it/s]\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tqdm(description_tokens))\n",
    "dictionary.filter_extremes(no_below=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9666/9666 [00:02<00:00, 3826.47it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(token) for token in tqdm(description_tokens)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build LDA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell takes a long time to run. Would you like to skip it? (y/n)y\n"
     ]
    }
   ],
   "source": [
    "response = input('This cell takes a long time to run. Would you like to skip it? (y/n)')\n",
    "if response.lower() == 'y':\n",
    "    pass\n",
    "elif response.lower() =='n':\n",
    "    np.random.seed(42)\n",
    "    eta = [0.01]*len(dictionary.keys())\n",
    "    for num_topics in tqdm(range(2,31)):\n",
    "        alpha = [0.01]*num_topics\n",
    "        lda_model = LdaModel(\n",
    "            corpus, \n",
    "            num_topics=num_topics,\n",
    "            id2word=dictionary,\n",
    "            passes=4, \n",
    "            alpha=alpha,\n",
    "            eta=eta\n",
    "        )\n",
    "        file_path = f'../model/LDA-{num_topics}topics'\n",
    "        lda_model.save(file_path)\n",
    "else:\n",
    "    print('Could not interpret response. Run cell again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning the number of topics for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Latent Dirichlet Allocation model tries to learn a fixed number of latent topics from a corpus of texts. In order to produce the best possible representation of our Job descriptions it is important to select an appropriate number of topics. \n",
    "\n",
    "We will use two measures of model quality to select the number of topics for our final model. First, mean Jaccard similarity of topics, which essentially measures how much overlap there is between topics. A lower value of this measure indicates a better model. Second, coherence of topics, which essentially measures how internally consistent the top words are from each topic. A higher value of this measure indicates a better model.\n",
    "\n",
    "Both measures return values in the range from zero to one and we will select the number of topics which produces the largest difference of coherence minus Jaccard similarity, preferring fewer topics in the case of a near tie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute both measures for each saved LDA model, we call the `get_measures` method from the `topic_selection` module. This method takes substantial time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def get_measures(texts, dictionary):\n",
       "    \"\"\"get_measures. Collects Jaccard similarity and coherence for all trained\n",
       "    LDA models.\n",
       "\n",
       "    Parameters\n",
       "    ----------\n",
       "    model:\n",
       "        A trained LDA model. Takes input from get_model.\n",
       "    texts :\n",
       "        texts\n",
       "    dictionary :\n",
       "        dictionary\n",
       "    \"\"\"\n",
       "    measures_list = {\n",
       "        'n': [],\n",
       "        'mean_jaccard': [],\n",
       "        'coherence': []        \n",
       "    }\n",
       "    for n in tqdm(range(2,31)):\n",
       "        model = get_model(n)\n",
       "        topics = get_topics(model)\n",
       "        measures_list['n'].append(n)\n",
       "        measures_list['mean_jaccard'].append(mean_jaccard_similarity(topics)),\n",
       "        measures_list['coherence'].append(get_coherence(model, texts, dictionary))\n",
       "    return measures_list\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import topic_selection\n",
    "display_object(topic_selection.get_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell takes a long time to run. Would you like to skip it? (y/n)y\n"
     ]
    }
   ],
   "source": [
    "response = input('This cell takes a long time to run. Would you like to skip it? (y/n)')\n",
    "if response.lower() == 'y':\n",
    "    pass\n",
    "elif response.lower() =='n':\n",
    "    measures_list = topic_selection.get_measures(description_tokens, dictionary)\n",
    "    with open('../model/measures.pkl', mode='wb') as file:\n",
    "        pickle.dump(measures_list, file)\n",
    "else:\n",
    "    print('Could not interpret response. Run cell again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c9ab396e983b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../model/measures.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmeasures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmeasures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmeasures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diff'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coherence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeasures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_jaccard'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open('../model/measures.pkl', mode='rb') as file:\n",
    "    measures = pickle.load(file)\n",
    "    \n",
    "measures_df = pd.DataFrame(measures)\n",
    "measures_df['diff'] = measures_df['coherence'] - measures_df['mean_jaccard']\n",
    "px.line(\n",
    "    data_frame = measures_df,\n",
    "    x = 'n',\n",
    "    y = ['mean_jaccard', 'coherence', 'diff'],\n",
    "    title = 'latent dirichlet allocation topic number selection'.title(),\n",
    "    labels = {\n",
    "        'n': 'Number of Topics',\n",
    "        'variable': 'Metric'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Selection of number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on our selection criterion and the plot above we select 28 topics for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_topics = 28\n",
    "lda_model = topic_selection.get_model(num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It might be advisable to investigate models with a number of topics greater than 28 in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### K-Means Clustering of Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Computing topic distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the cell below, we use our LDA model to compute topic distributions for our corpus of job descriptions. Each job description is represented as a 28 dimensional probability vector, which describes the mixture of topics present in the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_topic_distributions(lda_model, corpus):\n",
    "    rows = []\n",
    "    for description in tqdm(corpus):\n",
    "        topics = lda_model.get_document_topics(description)\n",
    "        vec = np.zeros(num_topics)\n",
    "        for key, prob in topics:\n",
    "            vec[key] = prob\n",
    "        rows.append(vec)\n",
    "    topic_distributions = np.array(rows)\n",
    "    return topic_distributions\n",
    "\n",
    "topic_distributions = get_topic_distributions(lda_model, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Tuning the number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For our K-means clustering model we need to select an appropriate number of clusters. To this end we will compute three well regarded measures of clustering quality: Calinski Harabasz Score, Within Cluster Sum of Squares, and Silhouette Score. We will select a number of clusters where one or more of these measures exhibits a marked change in trend, we will prefer fewer clusters if there are multiple candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Computing measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_measures(topic_distributions):\n",
    "    measures = {\n",
    "        'n_clusters': [],\n",
    "        'CH_score': [],\n",
    "        'WCSS_score': [],\n",
    "        'S_score': []\n",
    "    }\n",
    "\n",
    "    for n_clusters in tqdm(range(2, 40)):\n",
    "        clusterer = KMeans(n_clusters=n_clusters)\n",
    "        preds = clusterer.fit_predict(topic_distributions)\n",
    "        measures['CH_score'].append(calinski_harabasz_score(topic_distributions, preds))\n",
    "        measures['WCSS_score'].append(clusterer.inertia_)\n",
    "        measures['S_score'].append(silhouette_score(topic_distributions,preds))\n",
    "        measures['n_clusters'].append(n_clusters)\n",
    "    return measures\n",
    "\n",
    "measures = get_measures(topic_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "km_measures_df = pd.DataFrame(measures)\n",
    "fig = px.line(\n",
    "    data_frame = km_measures_df,\n",
    "    x='n_clusters', \n",
    "    y=['CH_score', 'WCSS_score'], \n",
    "    title='K-means Quality Measures',\n",
    "\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame = km_measures_df,\n",
    "    x='n_clusters', \n",
    "    y='S_score', \n",
    "    title='Silhouette Score',\n",
    "    labels ={\n",
    "        'n_clusters': 'Number of Clusters',\n",
    "        'S_score': 'Silhouette Score'\n",
    "    }\n",
    ")    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Selecting the number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The most marked change in trend is in the Silhouette Score at twelve clusters, so we select this value for our number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 13\n",
    "km_model = KMeans(num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Multinomial Naive Bayes Classification of Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Convert title tokens to word count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "titles = [' '.join(title_list) for title_list in title_tokens]\n",
    "X = vectorizer.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Assign job classes using K-means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = km_model.fit_predict(topic_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Perform train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Define gridsearch over $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The parameter $\\alpha$ is a smoothing parameter, by default the Multinomial Naive Bayes' classifier uses Laplace smoothing, which corresponds to $\\alpha = 1$ we also test Lidstone smoothing with $\\alpha = 10^{-5}, 0.01, 0.1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "param_grid = {'alpha' : [1e-5, 1e-2, 1e-1, 1]}\n",
    "grid = GridSearchCV(clf, param_grid, scoring='accuracy', n_jobs=-1, cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grid_df = pd.DataFrame(grid.cv_results_)\n",
    "px.line(\n",
    "    data_frame = grid_df,\n",
    "    x = 'param_alpha',\n",
    "    y = 'mean_test_score'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Selecting best Multinomial Naive Bayes' model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we saw above the best value of $\\alpha$ was $0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mnb_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having built our models. We wish to asses our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting LDA Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = DataProcessor.get_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting Job Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimated Accuracy of Classifying Jobs by Title\n",
    "Below we see that our best estimate for the accuracy of classifying data industry job postings by job title is 53%. So we would expect that a job seeker will incorrectly classify a job posting about half of the time when skimming job titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = mnb_model.predict(X_test)\n",
    "score_test = mnb_model.score(X_test, y_test)\n",
    "px.imshow(\n",
    "    confusion_matrix(y_test, pred_test),\n",
    "    title = f'Test Set Confusion Matrix (Accuracy {round(score_test,2)})',\n",
    "    color_continuous_scale='Blues',\n",
    "    height = 800,\n",
    "    width = 800,\n",
    "    labels = {\n",
    "        'x': 'Predicted',\n",
    "        'y': 'Observed',\n",
    "        'color': 'Frequency'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Results\n",
    "\n",
    "### Review \n",
    "\n",
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "### Deployment Plan\n",
    "\n",
    "### Monitoring and Maintenance\n",
    "\n",
    "### Report\n",
    "\n",
    "### Project Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JobDash",
   "language": "python",
   "name": "jobdash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
